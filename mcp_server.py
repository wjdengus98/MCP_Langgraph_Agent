"""
MCP Server - AI Agentë¥¼ ìœ„í•œ ë„êµ¬ ëª¨ìŒ

ì œê³µí•˜ëŠ” ë„êµ¬:
1. scrape_page_text: ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ ìŠ¤í¬ë˜í•‘
2. get_weather: ë„ì‹œë³„ ë‚ ì”¨ ì¡°íšŒ
3. get_news_headlines: êµ¬ê¸€ RSS ë‰´ìŠ¤ í—¤ë“œë¼ì¸
4. get_kbo_rank: KBO í”„ë¡œì•¼êµ¬ ìˆœìœ„
5. today_schedule: ì˜¤ëŠ˜ì˜ ì¼ì • (Mock ë°ì´í„°) -> ë…¸ì…˜, êµ¬ê¸€ ìŠ¤ì¼€ì¤„ëŸ¬ ì—°ë™
6. daily_quote: ì˜ê°ì„ ì£¼ëŠ” ëª…ì–¸ ìƒì„±
7. brief_today: ì¢…í•© ë¸Œë¦¬í•‘ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
"""

import json
import logging
from typing import Optional
import feedparser
import httpx
from bs4 import BeautifulSoup
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from mcp.server.fastmcp import FastMCP
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
from tenacity import retry, stop_after_attempt, wait_exponential
from dotenv import load_dotenv
import os

# í™˜ê²½ ì„¤ì •
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
mcp = FastMCP("MCP-Agent-Server")

# ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ë„êµ¬
@mcp.tool()
def scrape_page_text(url:str) -> str:
    """ì›¹í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ìŠ¤í¬ë©
    
        Args:
            url: ìŠ¤í¬ë©í•  ì›¹í˜ì´ì§€ URL
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸ or ì—ëŸ¬ë©”ì‹œì§€
    """
    try:
        logger.info(f"ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘: {url}")
            
        #User agent í—¤ë” ì¶”ê°€ (ì‚¬ì´íŠ¸ ì°¨ë‹¨ ë°©ì§€)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        resp = httpx.get(url, headers=headers, timeout=10.0, follow_redirects=True)
        resp.raise_for_status()
        
        soup = BeautifulSoup(resp.text, "html.parser")
        
        # script, style, nav, footer, header ë¡œ ê°ì‹¸ì ¸ìˆëŠ” tag ì œê±°
        for tag in soup(['script', 'style', 'nav', 'footer', 'header']):
            tag.decompose()
        
        if soup.body:
            text = soup.body.get_text(separator=" ", strip=True)
            cleaned_text = " ".join(text.split())
            
            logger.info(f"ìŠ¤í¬ë˜í•‘ ì™„ë£Œ {len(cleaned_text)} ì ì¶”ì¶œ")
            return cleaned_text[:5000]
        
        return "ë³¸ë¬¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    except httpx.HTTPStatusError as e:
        error_msg = f"HTTP ì—ëŸ¬ ë°œìƒ: {e.response.status_code}"
        logger.error(error_msg)
        return error_msg
    except httpx.TimeoutException:
        error_msg = "ìš”ì²­ ì‹œê°„ ì´ˆê³¼: ì›¹í˜ì´ì§€ ì‘ë‹µì´ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤."
        logger.error(error_msg)
        return error_msg
    except Exception as e:
        error_msg = f"ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        return error_msg

# ë„ì‹œëª…ì„ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def get_coordinates(city_name: str) -> tuple[float, float]:
    """ë„ì‹œ ì´ë¦„ì„ ë°›ì•„ ìœ„ë„/ê²½ë„ë¥¼ ë°˜í™˜ í•˜ëŠ” í•¨ìˆ˜"""
    try:
        geolocator = Nominatim(user_agent="weather_app_langgraph")
        location = geolocator.geocode(city_name)
        
        if location:
            logger.info(f"ì¢Œí‘œ ì°¾ìŒ: {city_name} -> ({location.latitude}, {location.longitude})")
            return location.latitude, location.longitude
        raise ValueError(f"'{city_name}'ì˜ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„ì‹œ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    except (GeocoderTimedOut, GeocoderServiceError) as e:
        logger.warning(f"Geocoder ì—ëŸ¬: {e}, ì¬ì‹œë„ ì¤‘...")
        raise  # Retry ë°ì½”ë ˆì´í„°ê°€ ì²˜ë¦¬

@mcp.tool()
def get_weather(city_name:str) -> str:
    """ë„ì‹œ ì´ë¦„ì„ ë°›ì•„ í˜„ì¬ ë‚ ì”¨ ì •ë³´ ë°˜í™˜"""

    logger.info(f"ë‚ ì”¨ ì¡°íšŒ ì‹œì‘: {city_name}")
    
    # ìœ„ë„/ê²½ë„ ì¡°íšŒ
    latitude, longitude = get_coordinates(city_name)

    # OPEN METRO API
    url = f"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true&timezone=Asia%2FSeoul"
    
    response = httpx.get(url, timeout=10.0)
    response.raise_for_status()
    
    result = response.json()
    
    # ì‚¬ëŒì´ ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…
    current = result.get('current_weather', {})
    weather_info = {
        "ë„ì‹œ": city_name,
        "ì˜¨ë„": f"{current.get('temperature', 'N/A')}Â°C",
        "í’ì†": f"{current.get('windspeed', 'N/A')} km/h",
        "ë‚ ì”¨ì½”ë“œ": current.get('weathercode', 'N/A'),
        "ì‹œê°„": current.get('time', 'N/A')
    }
    
    logger.info(f"ë‚ ì”¨ ì¡°íšŒ ì™„ë£Œ: {city_name} - {weather_info['ì˜¨ë„']}")
    return json.dumps(weather_info, ensure_ascii=False, indent=2)


#3. êµ¬ê¸€ ë‰´ìŠ¤ í—¤ë“œë¼ì¸
@mcp.tool()
def get_news_headlines(max_items: int = 10) -> str:
    """êµ¬ê¸€ RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ì™€ URL ë°˜í™˜""" 
    try:
        logger.info(f"ë‰´ìŠ¤ ì¡°íšŒ ì‹œì‘ ìµœëŒ€ {max_items}ê°œ")
        
        rss_url = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko"
        feed = feedparser.parse(rss_url)
        
        if not feed.entries:
            return "ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        news_list =[]
        for i, entry in enumerate(feed.entries[:max_items], 1):
            title = getattr(entry, "title", "ì œëª© ì—†ìŒ")
            link = getattr(entry, "link", "#")
            
            # None ê°’ ì²˜ë¦¬
            if not title or title == None:
                title = "ì œëª© ì—†ìŒ"
            if not link or link == None:
                link = "#"
            
            # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ í¬ë§·íŒ…
            news_item = f"{i}. [{title}]({link})"
            news_list.append(news_item)
            
        logger.info(f"ë‰´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {len(news_list)}ê°œ í•­ëª©")
        
        # ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
        return "\n".join(news_list)
    
    except Exception as e:
        error_msg = f"ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        return error_msg

#4. KBO í”„ë¡œì•¼êµ¬ ìˆœìœ„ ê°€ì ¸ì˜¤ê¸°
@mcp.tool()
def get_kbo_rank() -> str:
    """
    í•œêµ­ í”„ë¡œì•¼êµ¬(KBO) êµ¬ë‹¨ì˜ í˜„ì¬ ìˆœìœ„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Returns:
        KBO ìˆœìœ„ ì •ë³´ JSON ë¬¸ìì—´
    """
    try:
        logger.info("KBO ìˆœìœ„ ì¡°íšŒ ì‹œì‘")
        
        # 2025 ì‹œì¦Œ -> 2026 ì‹œì¦Œ ì—…ë°ì´íŠ¸ ì•ˆë¨.
        url = "https://sports.daum.net/prx/hermes/api/team/rank.json?leagueCode=kbo&seasonKey=2025"
        
        response = httpx.get(url, timeout=10.0)
        response.raise_for_status()
        
        # Json íŒŒì‹±
        data = response.json()
        teams = data.get('list', [])
        
        if not teams:
            return "KBO ìˆœìœ„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìˆœìœ„í‘œ ìƒì„±
        result = []
        result.append("## ğŸ“Š 2025 KBO ë¦¬ê·¸ ìˆœìœ„\n")
        
        for team in teams:
            rank_info = team.get("rank", {})
            name = team.get("shortName", "íŒ€ëª… ì—†ìŒ")
            
            # ê° íŒ€ ì •ë³´ í¬ë§·íŒ…
            rank_line = (
                f"{rank_info.get('rank')}ìœ„: {name} - "
                f"{rank_info.get('win')}ìŠ¹ {rank_info.get('loss')}íŒ¨ "
                f"(ìŠ¹ë¥  {rank_info.get('wpct'):.3f}, {rank_info.get('streak')})"
            )
            result.append(rank_line)      
            
        logger.info("KBO ìˆœìœ„ ì¡°íšŒ ì™„ë£Œ")
        return "\n".join(result)
        
    except Exception as e:
        error_msg = f"KBO ìˆœìœ„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        return error_msg

#5. ì¼ì • ê°€ì ¸ì˜¤ê¸°(Mock data -> ë…¸ì…˜,êµ¬ê¸€ ìŠ¤ì¼€ì¤„ ì—°ë™(update ì˜ˆì •))
@mcp.tool()
def today_schedule() -> str:
    """ì¼ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    events = [
            "09:00 - ë°ì¼ë¦¬ ìŠ¤íƒ ë“œì—… ë¯¸íŒ…",
            "10:30 - LangGraph í•™ìŠµ ì‹œê°„",
            "13:00 - ì ì‹¬ ì•½ì† (ê°•ë‚¨ì—­)",
            "15:00 - MCP í”„ë¡œì íŠ¸ ê°œë°œ",
            "18:00 - ìš´ë™ (í—¬ìŠ¤ì¥)",
            "20:00 - ì €ë… ì‹ì‚¬"
        ]
    result = "\n".join([f"{event}" for event in events])
    logger.info(f"ì¼ì • ì¡°íšŒ ì™„ë£Œ: {len(events)}ê°œ í•­ëª©")
    
    return result

#6. ì˜ê°ì„ ì£¼ëŠ” ëª…ì–¸
@mcp.tool()
def daily_quote() -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ëŠ˜ì˜ ì˜ê°ì„ ì£¼ëŠ” ëª…ì–¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    model_name = os.getenv("LLM_MODEL", "gpt-5-mini")
    
    chat_model = ChatOpenAI(model=model_name, temperature=0.8)
    
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ë‹¹ì‹ ì€ ì˜¤ëŠ˜ í•˜ë£¨ì˜ ëª…ì–¸ì„ ì•Œë ¤ì£¼ê³  ì‘ì›í•˜ëŠ” ë”°ëœ»í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
                "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n\n"
                "ğŸ’¡ ì˜¤ëŠ˜ì˜ ëª…ì–¸\n"
                "\"[ëª…ì–¸ ë‚´ìš©]\" - [ì €ì]\n\n"
                "ğŸ’ª ì‘ì›ì˜ í•œë§ˆë””\n"
                "[ëª…ì–¸ì˜ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì‘ì›í•˜ëŠ” 2-3ì¤„ ë©”ì‹œì§€]\n\n"
                "ì§„ì‹¬ ì–´ë¦° ê²©ë ¤ì™€ ë”°ëœ»í•¨ì´ ë‹´ê¸´ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
            ),
            ("human", "ì˜¤ëŠ˜ì˜ ëª…ì–¸ê³¼ ì‘ì› ë©”ì‹œì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.")
        ]
    )
    
    chain = prompt | chat_model
    response = chain.invoke({})
    
    logger.info("ëª…ì–¸ ìƒì„± ì™„ë£Œ")
    return response.content

# 7. ì¢…í•© ë¸Œë¦¬í•‘
@mcp.tool()
def brief_today() -> str:
    """
    ì‚¬ìš©ìì˜ í•˜ë£¨ ì‹œì‘ì„ ë•ê¸° ìœ„í•´ ë‚ ì”¨, ë‰´ìŠ¤, ì¼ì •, ëª…ì–¸ì„ ì¢…í•©í•˜ì—¬ ì „ë‹¬í•©ë‹ˆë‹¤.
    
    Returns:
        ë¸Œë¦¬í•‘ ì§€ì¹¨ ë¬¸ìì—´
    """
    return """
## ğŸ“‹ ì˜¤ëŠ˜ì˜ ë¸Œë¦¬í•‘ ìƒì„± ê°€ì´ë“œ

ë‹¤ìŒ ìˆœì„œëŒ€ë¡œ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”:

### 1ë‹¨ê³„: ìœ„ì¹˜ í™•ì¸
- ì‚¬ìš©ìì˜ ìœ„ì¹˜(ë„ì‹œ)ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
- ìœ„ì¹˜ë¥¼ ëª¨ë¥¸ë‹¤ë©´, ë¨¼ì € ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”.

### 2ë‹¨ê³„: ë‚ ì”¨ ì¡°íšŒ
- `get_weather(ë„ì‹œëª…)` ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.

### 3ë‹¨ê³„: ë‰´ìŠ¤ ì¡°íšŒ
- `get_news_headlines()` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.

### 4ë‹¨ê³„: ì•¼êµ¬ ìˆœìœ„
- `get_kbo_rank()` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ KBO ë¦¬ê·¸ ìˆœìœ„ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.

### 5ë‹¨ê³„: ì¼ì • í™•ì¸
- `today_schedule()` ë„êµ¬ë¡œ ì˜¤ëŠ˜ì˜ ì¼ì •ì„ í™•ì¸í•˜ì„¸ìš”.

### 6ë‹¨ê³„: ëª…ì–¸
- `daily_quote()` ë„êµ¬ë¡œ ì˜¤ëŠ˜ì˜ ëª…ì–¸ì„ ê°€ì ¸ì˜¤ì„¸ìš”.

### ì¶œë ¥ í˜•ì‹
ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±í•´ì£¼ì„¸ìš”:

---

# ğŸŒ… [ì‚¬ìš©ìë‹˜]ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ ë¸Œë¦¬í•‘

## â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨
[get_weather ê²°ê³¼]

## ğŸ“° ì£¼ìš” ë‰´ìŠ¤
[get_news_headlines ê²°ê³¼]

## âš¾ KBO ë¦¬ê·¸ ìˆœìœ„
[get_kbo_rank ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…]

## ğŸ“… ì˜¤ëŠ˜ì˜ ì¼ì •
[today_schedule ê²°ê³¼]

## ğŸ’¡ ì˜¤ëŠ˜ì˜ ëª…ì–¸
[daily_quote ê²°ê³¼]

---

ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸ˜Š
"""



if __name__ == "__main__":
    # url test
    # url = "https://quotes.toscrape.com"
    
    # result = scrape_page_text(url)
    # print(f"ê²°ê³¼: {result}")
    #====================================================================
    # get weather test
    # city = "ì„œìš¸"
    
    # result = get_weather(city)
    # print(result)
    
    #=====================================================
    # get headline ë‰´ìŠ¤ í…ŒìŠ¤íŠ¸
    # result = get_news_headlines()
    # lines = result.split("\n")
    
    # for line in lines:
    #     print(line)
    
    #============ kbo ===============
    # result = get_kbo_rank()
    # print(result)
    
    # =========Schedule test===============
    # result = today_schedule()
    # print(result)
    
    # ============= model test =============
    # result = daily_quote()
    # print(f"ëª¨ë¸ì˜ ì‘ë‹µ: {result}")
    
    #=========== MCP ì„œë²„ í…ŒìŠ¤íŠ¸ =============
    mcp.run(transport="streamable-http")

